{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format of the dataÂ¶\n",
    "    - last coloumn of the data frame must contain the label and it must also be called label\n",
    "    - there should be no missing values in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df = df.drop(\"Id\",axis = 1)\n",
    "df = df.rename(columns= {\"species\":\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df,test_size):\n",
    "    \n",
    "    if isinstance(test_size,float):\n",
    "        test_size = round(test_size*len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices,k = test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.seed(0)\n",
    "#train_df,test_df = train_test_split(df,test_size= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = train_df.values\n",
    "#data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:,-1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    \n",
    "    label_column = data[:,-1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column,return_counts= True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential slits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _,n_columns = data.shape\n",
    "\n",
    "    for column_index in range(n_columns - 1):\n",
    "        potential_splits[column_index] = []\n",
    "        values = data[:,column_index]\n",
    "        unique_values = np.unique(values)\n",
    "\n",
    "        for index in range(len(unique_values)):\n",
    "            if index != 0:\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index-1]\n",
    "                potential_split =(current_value + previous_value ) / 2\n",
    "\n",
    "                potential_splits[column_index].append(potential_split)\n",
    "\n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#potential_splits = get_potential_splits(train_df.values)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lmplot(data=train_df,x = \"petal_width\", y = \"petal_length\",hue = \"label\",fit_reg = False, size = 6, aspect = 1.5)\n",
    "\n",
    "#plt.vlines(x = potential_splits[3], ymin=1,ymax= 7)\n",
    "#plt.hlines(y = potential_splits[2], xmin=0,xmax= 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,split_column,split_value):\n",
    "    \n",
    "    split_column_values = data[:,split_column]\n",
    "\n",
    "    data_below = data[split_column_values <= split_value]\n",
    "    data_above = data[split_column_values > split_value]\n",
    "                      \n",
    "    return data_below,data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_column = 3\n",
    "split_value = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_below,data_above = split_data(data,split_column,split_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting_df = pd.DataFrame(data_below,columns= df.columns)\n",
    "#sns.lmplot(data=plotting_df,x = \"petal_width\",y = \"petal_length\",fit_reg = False, size = 6, aspect = 1.5)\n",
    "#plt.vlines(x = split_value, ymin= 1, ymax= 7)\n",
    "#plt.xlim(0,2.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowest Overall Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:,-1]\n",
    "    _,counts = np.unique(label_column,return_counts = True)\n",
    "\n",
    "    probabilities = counts/counts.sum()\n",
    "    entropy = sum(probabilities* -np.log2(probabilities))\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below,data_above):\n",
    "    \n",
    "    n_data_points = len(data_below) + len(data_above)\n",
    "\n",
    "    p_data_below= len(data_below)/n_data_points\n",
    "    p_data_above= len(data_above)/n_data_points\n",
    "\n",
    "    overall_entropy = (p_data_below * calculate_entropy(data_below) + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate_overall_entropy(data_below,data_above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data,potential_splits):\n",
    "    \n",
    "    overall_entropy = 999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below,data_above = split_data(data,split_column = column_index,split_value = value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below,data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "\n",
    "    return best_split_column,best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#potential_splits = get_potential_splits(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine_best_split(data,potential_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dictionary = {question : [yes_answer,no_answer]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example_tree = {\"petal_width <= 0.8\":[\"Iris-setosa\",\n",
    "                                     {\"petal_width <= 1.65\": [{\"petal_width <= 4.9\" : [\"Iris-versicolor\",\n",
    "                                                                                      \"Iris-virginica\"]},\n",
    "                                                             \"Iris-virginica\"]}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df,counter = 0,min_samples = 2 , ):\n",
    "    \n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global column_headers\n",
    "        column_headers = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    # base case\n",
    "    if (check_purity(data)) or (len(data) < min_samples):\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        counter += 1\n",
    "        \n",
    "        # helper functions\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data,potential_splits)\n",
    "        data_below,data_above = split_data(data,split_column,split_value)\n",
    "        \n",
    "        # instantiate subtree\n",
    "        feature_name = column_headers[split_column]\n",
    "        question = \"{} <= {}\".format(feature_name,split_value)\n",
    "        subtree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below,counter, min_samples)\n",
    "        no_answer = decision_tree_algorithm(data_above,counter, min_samples)\n",
    "        \n",
    "        subtree[question].append(yes_answer)\n",
    "        subtree[question].append(no_answer)\n",
    "        \n",
    "        return subtree\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'petal_width <= 0.8': ['Iris-setosa',\n",
      "                        {'petal_width <= 1.65': ['Iris-versicolor',\n",
      "                                                 'Iris-virginica']}]}\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_algorithm(train_df, min_samples=60)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'label'], dtype='object')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
